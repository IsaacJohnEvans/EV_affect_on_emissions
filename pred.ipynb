{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, metrics\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(em_data = True, veh_data = True, air_data = True):\n",
    "    args = []\n",
    "    if em_data:\n",
    "        EU_em_df = pd.read_excel('Data/EU_em.xlsx',engine='openpyxl')\n",
    "        EU_em_annual_df = pd.read_csv('Data/EU_em_annual.csv',)\n",
    "        UK_em_df = pd.read_excel('Data/UK_em.ods', nrows = 16)\n",
    "        US_em_df = pd.read_excel('Data/US_em.xlsx',engine='openpyxl')\n",
    "        # Emissions data Processing\n",
    "        EU_em_df = EU_em_df.set_index('Month')\n",
    "        EU_em_annual_df = EU_em_df.groupby(np.arange(len(EU_em_df))//(12)).sum()\n",
    "        EU_em_annual_df.index = np.linspace(1973, 2021, EU_em_annual_df.shape[0], dtype=np.int32)\n",
    "        UK_em_df = UK_em_df.transpose()\n",
    "        UK_em_df.columns = UK_em_df.iloc[0, :]\n",
    "        UK_em_df = UK_em_df.drop('Year')\n",
    "        US_em_df = US_em_df.transpose()\n",
    "        US_em_df.columns = US_em_df.iloc[0, :]\n",
    "        US_em_df = US_em_df.drop('Gas/Vehicle')\n",
    "        args += [EU_em_df, EU_em_annual_df, UK_em_df, US_em_df]\n",
    "    if veh_data:\n",
    "        EU_veh_df = pd.read_csv('Data/EU_veh.csv')\n",
    "        UK_veh_df = pd.read_excel('Data/UK_veh.ods', nrows= 76)\n",
    "        US_veh_df = pd.read_excel('Data/US_veh.xlsx')\n",
    "        args += [EU_veh_df, UK_veh_df, US_veh_df]\n",
    "    if air_data:\n",
    "        # Secondary Data \n",
    "        # Air pollution\n",
    "        # UK 1970-2019/2022\n",
    "        UK_nox_annual_df = pd.read_csv('Data/Figure06_NOx_time_series.csv')\n",
    "        UK_pm_all_annual_df = pd.read_csv('Data/Figure03_PM_time_series.csv')\n",
    "                \n",
    "        # USA Since 1970-2020, plz Access through column id(numbers)\n",
    "        USA_nox_annual_df = pd.read_csv('Data/US_nox_em_time_series.csv') # National Emissions Totals (thousands of tons)\n",
    "        USA_pm_10_annual_df = pd.read_csv('Data/US_pm10_year.csv')        #\n",
    "        USA_pm_2_5_annual_df = pd.read_csv('Data/US_pm2_5_year.csv')\n",
    "        \n",
    "        USA_pm_2_5_annual_df = USA_pm_2_5_annual_df.transpose()\n",
    "        USA_pm_10_annual_df = USA_pm_10_annual_df.transpose()\n",
    "                \n",
    "        # OCED DATA\n",
    "        OCED_PM10_df = pd.read_excel('Data/PM10_ROAD_OCED_WORLD_DATA.xlsx')\n",
    "        OCED_NOX_df = pd.read_excel('Data/NOX_ROAD_OCED_WORLD_DATA.xlsx')\n",
    "        OCED_PM2_5_df = pd.read_excel('Data/PM2_5_ROAD_OCED_WORLD_DATA.xlsx')\n",
    "    \n",
    "    args += [UK_nox_annual_df,UK_pm_all_annual_df,USA_pm_10_annual_df,USA_pm_2_5_annual_df,USA_nox_annual_df,OCED_PM10_df,OCED_NOX_df,OCED_PM2_5_df]\n",
    "        \n",
    "    return args\n",
    "\n",
    "def train_test_split(X, y, split_point):\n",
    "    x_train = X[:split_point, :, :]\n",
    "    x_test = X[split_point:, :, :]\n",
    "    y_train = y[:split_point]\n",
    "    y_test = y[split_point:]\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def normalise(X):\n",
    "    X_attrs = np.zeros((X.shape[-1], 2))\n",
    "    for i in range(X.shape[-1]):\n",
    "        X_attrs[i, :] = [np.mean(X[:, i]), np.var(X[:, i])]\n",
    "        X[:, i] = (X[:, i] - np.mean(X[:, i]))/np.var(X[:, i])**0.5\n",
    "    return X, X_attrs\n",
    "        \n",
    "def create_model(layers, input_shape):\n",
    "    # Create and compile model\n",
    "    model = keras.Sequential(layers)\n",
    "    model.build(input_shape=input_shape)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Apps\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "args = load_data()\n",
    "EU_em_df, EU_em_annual_df, UK_em_df, US_em_df, EU_veh_df, UK_veh_df, US_veh_df, UK_nox_annual_df,UK_pm_all_annual_df,USA_pm_10_annual_df,USA_pm_2_5_annual_df,USA_nox_annual_df,OCED_PM10_df,OCED_NOX_df,OCED_PM2_5_df = args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 1\n",
    "data_memory = 5\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "df_model_columns =  ['time_step', 'data_memory', 'samples', 'layers', 'training_loss', 'val_loss', 'test_loss']\n",
    "#model_df = pd.DataFrame(model_performance).transpose()\n",
    "#model_df.to_csv('model_performance.csv')\n",
    "X = EU_em_df.to_numpy()\n",
    "X_norm, X_attrs = normalise(X)\n",
    "X_norm, y_norm = np.split(X, [11], 1)\n",
    "y_norm = np.roll(y_norm, - time_step)\n",
    "nrows = X_norm.shape[0]\n",
    "samples = X_norm.shape[1]\n",
    "X_norm = np.repeat(X_norm, data_memory, 0).reshape(nrows, data_memory, samples)\n",
    "split_point = int(X_norm.shape[0] *0.75)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_norm, y_norm, split_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.dense.Dense object at 0x00000256557EFD30>\n"
     ]
    }
   ],
   "source": [
    "model_layer = [layers.Dense(32, activation='sigmoid')]\n",
    "print(str(model_layer[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_58 (Dense)            (439, 5, 32)              384       \n",
      "                                                                 \n",
      " gru_27 (GRU)                (439, 32)                 6336      \n",
      "                                                                 \n",
      " dense_59 (Dense)            (439, 1)                  33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,753\n",
      "Trainable params: 6,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 2s 10ms/step - loss: 0.8045 - val_loss: 2.2721\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5214 - val_loss: 1.2627\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2364 - val_loss: 0.4871\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1314 - val_loss: 0.2728\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1213 - val_loss: 0.3053\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1188 - val_loss: 0.3013\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1204 - val_loss: 0.2552\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1162 - val_loss: 0.2266\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1159 - val_loss: 0.2463\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1125 - val_loss: 0.2203\n",
      "0.14342792\n"
     ]
    }
   ],
   "source": [
    "input_shape = (x_train.shape[0], data_memory, samples)\n",
    "model_layer = [layers.Dense(32, activation='sigmoid'),\n",
    "               layers.GRU(32, activation='sigmoid', recurrent_activation='sigmoid'),\n",
    "               layers.Dense(1)]\n",
    "model_des = 'D32, GRU32, D1'\n",
    "model = create_model(model_layer, input_shape)\n",
    "history = model.fit(x_train, y_train, validation_split = 0.1, epochs= epochs , batch_size=batch_size)\n",
    "y_pred_norm = np.concatenate((model.predict(x_train[:, :, :]), model.predict(x_test[:, :, :])))\n",
    "mse = metrics.MeanSquaredError()\n",
    "mse.update_state(y_norm, y_pred_norm)\n",
    "test_loss = mse.result().numpy()\n",
    "y = (y_norm/X_attrs[-1, 1]**0.5) + X_attrs[-1, 0]\n",
    "y_pred = y_pred_norm /X_attrs[-1, 1]**0.5 + X_attrs[-1, 0]  \n",
    "print(test_loss)\n",
    "model_performance = [time_step, data_memory, samples, model_des, epochs, batch_size, test_loss]\n",
    "df_model = pd.DataFrame(model_performance).transpose()\n",
    "df_model.columns = df_model_columns\n",
    "df_model.to_csv('model_performance.csv', mode = 'a', header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_range = [440]\n",
    "plot_range += [plot_range[0] + 20]\n",
    "t = np.linspace(plot_range[0], plot_range[1], plot_range[1] - plot_range[0])\n",
    "plt.plot(t, y[plot_range[0] : plot_range[1]], 'g', t, y_pred[plot_range[0]: plot_range[1]], 'r')\n",
    "split_point"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cabb15ab25fea23f8059180816881b2dbbe348c8bd98378d45c058900a30581"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
